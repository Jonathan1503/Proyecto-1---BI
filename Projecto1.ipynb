{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecto 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Jonathan Rivera\n",
    "* Julian Castro  \n",
    "* Alejandro Gomez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Ministerio de Comercio, Industria y Turismo de Colombia, la Asociación Hotelera y\n",
    "Turística de Colombia – COTELCO, cadenas hoteleras de la talla de Hilton, Hoteles Estelar,\n",
    "Holiday Inn y hoteles pequeños ubicados en diferentes municipios de Colombia están\n",
    "interesados en analizar las características de sitios turísticos que los hacen atractivos para\n",
    "turistas locales o de otros países, ya sea para ir a conocerlos o recomendarlos. De igual\n",
    "manera, quieren comparar las características de dichos sitios, con aquellos que han\n",
    "obtenido bajas recomendaciones y que están afectando el número de turistas que llegan a\n",
    "ellos. Adicionalmente, quieren tener un mecanismo para determinar la calificación que\n",
    "tendrá un sitio por parte de los turistas y así, por ejemplo, aplicar estrategias para identificar\n",
    "oportunidades de mejora que permitan aumentar la popularidad de los sitios y fomentar el\n",
    "turismo.\n",
    "Esos actores de turismo prepararon dos conjuntos de datos con reseñas de sitios turísticos.\n",
    "Cada reseña tiene una calificación según el sentimiento que tuvo el turista al visitarlo. Estos\n",
    "actores quieren lograr un análisis independiente de los conjuntos de datos y al final del\n",
    "proyecto discutir sobre los grupos de científicos de datos e ingenieros de datos que\n",
    "acompañarán el desarrollo real de este proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plantear un modelo de prediccion de calificaiciones de reseñas, basado en el procesamiento de textos, con un algoritmo que identifique la relacion semantica entre palabras y las calificaciones numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\julia\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\julia\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\julia\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\julia\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\julia\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\julia\\anaconda3\\lib\\site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\julia\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-2.1.0-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting inflect\n",
      "  Downloading inflect-7.2.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\julia\\anaconda3\\lib\\site-packages (from inflect) (4.9.0)\n",
      "Collecting typeguard>=4.0.1\n",
      "  Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\julia\\anaconda3\\lib\\site-packages (from inflect) (8.10.0)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from typeguard>=4.0.1->inflect) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from importlib-metadata>=3.6->typeguard>=4.0.1->inflect) (3.6.0)\n",
      "Installing collected packages: typing-extensions, typeguard, inflect\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.9.0\n",
      "    Uninstalling typing-extensions-4.9.0:\n",
      "      Successfully uninstalled typing-extensions-4.9.0\n",
      "Successfully installed inflect-7.2.0 typeguard-4.2.1 typing-extensions-4.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.7.4-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp39-cp39-win_amd64.whl (122 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp39-cp39-win_amd64.whl (25 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp39-cp39-win_amd64.whl (483 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (23.2)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2\n",
      "  Downloading thinc-8.2.3-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp39-cp39-win_amd64.whl (6.6 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.3)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: colorama, catalogue, srsly, murmurhash, cymem, wasabi, typer, preshed, confection, cloudpathlib, blis, weasel, thinc, spacy-loggers, spacy-legacy, langcodes, spacy\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 colorama-0.4.6 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gensim in c:\\users\\julia\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Collecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\julia\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.3.4)\n",
      "Collecting pyfume\n",
      "  Downloading pyFUME-0.3.1-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (4.11.0)\n",
      "Collecting simpful\n",
      "  Downloading simpful-2.12.0-py3-none-any.whl (24 kB)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20445 sha256=f6cef033ca9b89856c606e402f2c06e716c922165e2a866e9238dd7ff1522404\n",
      "  Stored in directory: c:\\users\\julia\\appdata\\local\\pip\\cache\\wheels\\99\\66\\48\\d7ce0c6927f6abf167bbcdee537affc7b92c03632f78028411\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3530 sha256=5ffdd10d0291a210dcb05527c494906715708a8a9885b75a5add1fb98497171b\n",
      "  Stored in directory: c:\\users\\julia\\appdata\\local\\pip\\cache\\wheels\\d9\\c7\\71\\db1d4646d963b34c530667501d3d6f34c0825eaffae2f0f2cb\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: miniful, simpful, fst-pso, pyfume, FuzzyTM\n",
      "Successfully installed FuzzyTM-2.0.5 fst-pso-1.8.1 miniful-0.0.6 pyfume-0.3.1 simpful-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.10.1-py2.py3-none-any.whl (107 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.1.0)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-23.12.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.20.3)\n",
      "Collecting scikit-learn>=1.0.0\n",
      "  Downloading scikit_learn-1.4.1.post1-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.7.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-optimize) (23.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (2.2.0)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Installing collected packages: joblib, scikit-learn, pyaml, scikit-optimize\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "Successfully installed joblib-1.3.2 pyaml-23.12.0 scikit-learn-1.4.1.post1 scikit-optimize-0.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting es-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.7.0/es_core_news_md-3.7.0-py3-none-any.whl (42.3 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from es-core-news-md==3.7.0) (3.7.4)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.26.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.20.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.10.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.62.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (23.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.9.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: setuptools in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (58.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2023.11.17)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.1.1)\n",
      "Installing collected packages: es-core-news-md\n",
      "Successfully installed es-core-news-md-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_md')\n",
      "Requirement already satisfied: inflect in c:\\users\\julia\\anaconda3\\lib\\site-packages (7.2.0)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from inflect) (4.2.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\julia\\anaconda3\\lib\\site-packages (from inflect) (8.10.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\julia\\anaconda3\\lib\\site-packages (from inflect) (4.11.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from typeguard>=4.0.1->inflect) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from importlib-metadata>=3.6->typeguard>=4.0.1->inflect) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-plot\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-plot) (3.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-plot) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-plot) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.10 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-plot) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.20.3)\n",
      "Requirement already satisfied: six in c:\\users\\julia\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (2.2.0)\n",
      "Installing collected packages: scikit-plot\n",
      "Successfully installed scikit-plot-0.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting spacy-language-detectionNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading spacy_language_detection-0.2.1-py3-none-any.whl (6.5 kB)\n",
      "Collecting langdetect==1.0.9\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Requirement already satisfied: spacy>=3.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy-language-detection) (3.7.4)\n",
      "Requirement already satisfied: six in c:\\users\\julia\\anaconda3\\lib\\site-packages (from langdetect==1.0.9->spacy-language-detection) (1.16.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (0.9.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (1.0.10)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (1.20.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (1.10.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (8.2.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (1.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (23.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (5.2.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (0.3.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (2.0.8)\n",
      "\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (58.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (2.26.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy>=3.0.0->spacy-language-detection) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->spacy-language-detection) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->spacy-language-detection) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->spacy-language-detection) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->spacy-language-detection) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->spacy-language-detection) (2023.11.17)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.0->spacy-language-detection) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.0->spacy-language-detection) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy>=3.0.0->spacy-language-detection) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy>=3.0.0->spacy-language-detection) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy>=3.0.0->spacy-language-detection) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from jinja2->spacy>=3.0.0->spacy-language-detection) (1.1.1)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=77c296d56803de76c2e783d80a57b778fdeeecec68743247339a9e1fc138667e\n",
      "  Stored in directory: c:\\users\\julia\\appdata\\local\\pip\\cache\\wheels\\d1\\c1\\d9\\7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect, spacy-language-detection\n",
      "Successfully installed langdetect-1.0.9 spacy-language-detection-0.2.1\n",
      "Requirement already satisfied: pip in c:\\users\\julia\\anaconda3\\lib\\site-packages (21.2.4)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.1 requires ruamel-yaml, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\julia\\anaconda3\\lib\\site-packages (58.0.4)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
      "Requirement already satisfied: wheel in c:\\users\\julia\\anaconda3\\lib\\site-packages (0.37.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.0\n",
      "    Uninstalling wheel-0.37.0:\n",
      "      Successfully uninstalled wheel-0.37.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 58.0.4\n",
      "    Uninstalling setuptools-58.0.4:\n",
      "      Successfully uninstalled setuptools-58.0.4\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-24.0 setuptools-69.2.0 wheel-0.43.0\n",
      "Requirement already satisfied: spacy in c:\\users\\julia\\anaconda3\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.62.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.26.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: langdetect in c:\\users\\julia\\anaconda3\\lib\\site-packages (1.0.9)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: six in c:\\users\\julia\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install openpyxl\n",
    "%pip install contractions\n",
    "%pip install inflect\n",
    "%pip install spacy\n",
    "%pip install gensim\n",
    "%pip install scikit-optimize\n",
    "!python -m spacy download es_core_news_md\n",
    "%pip install inflect\n",
    "%pip install scikit-plot\n",
    "%pip install spacy-language-detection\n",
    "%pip install -U pip setuptools wheel\n",
    "%pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "! pip install langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# Punkt permite separar un texto en frases.\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"averaged_perceptron_tagger\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas-profiling\n",
      "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting ydata-profiling (from pandas-profiling)\n",
      "  Downloading ydata_profiling-4.7.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy<1.12,>=1.4.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.7.1)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.3.4)\n",
      "Requirement already satisfied: matplotlib<3.9,>=3.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (3.4.3)\n",
      "Collecting pydantic>=2 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "     -------------------------------------- 85.1/85.1 kB 680.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (6.0)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (2.11.3)\n",
      "Collecting visions<0.7.7,>=0.7.5 (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling->pandas-profiling)\n",
      "  Downloading visions-0.7.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.16.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.20.3)\n",
      "Collecting htmlmin==0.1.12 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting phik<0.13,>=0.11.1 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading phik-0.12.4-cp39-cp39-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (2.26.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (4.62.3)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (0.11.2)\n",
      "Collecting multimethod<2,>=1.4 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading multimethod-1.11.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting statsmodels<1,>=0.13.2 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading statsmodels-0.14.1-cp39-cp39-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: typeguard<5,>=4.1.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from ydata-profiling->pandas-profiling) (4.2.1)\n",
      "Collecting imagehash==4.3.1 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting wordcloud>=1.9.1 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading wordcloud-1.9.3-cp39-cp39-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting dacite>=1.8 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading dacite-1.8.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting numba<1,>=0.56.0 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading numba-0.59.1-cp39-cp39-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\julia\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (1.1.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\julia\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas-profiling) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (2.8.2)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba<1,>=0.56.0->ydata-profiling->pandas-profiling)\n",
      "  Downloading llvmlite-0.42.0-cp39-cp39-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting numpy<2,>=1.16.0 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "     -------------------------------------- 61.0/61.0 kB 806.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling->pandas-profiling) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas-profiling) (1.3.2)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2->ydata-profiling->pandas-profiling)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic>=2->ydata-profiling->pandas-profiling)\n",
      "  Downloading pydantic_core-2.16.3-cp39-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pydantic>=2->ydata-profiling->pandas-profiling) (4.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.2)\n",
      "Collecting numpy<2,>=1.16.0 (from ydata-profiling->pandas-profiling)\n",
      "  Downloading numpy-1.22.4-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting patsy>=0.5.4 (from statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling) (23.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tqdm<5,>=4.48.2->ydata-profiling->pandas-profiling) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from typeguard<5,>=4.1.2->ydata-profiling->pandas-profiling) (4.8.1)\n",
      "INFO: pip is looking at multiple versions of visions to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting visions<0.7.7,>=0.7.5 (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling->pandas-profiling)\n",
      "  Downloading visions-0.7.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling->pandas-profiling) (21.2.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling->pandas-profiling) (2.6.3)\n",
      "Collecting tangled-up-in-unicode>=0.0.4 (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling->pandas-profiling)\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "INFO: pip is looking at multiple versions of visions[type-image-path] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: six in c:\\users\\julia\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from importlib-metadata>=3.6->typeguard<5,>=4.1.2->ydata-profiling->pandas-profiling) (3.6.0)\n",
      "Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
      "   -------------------------------------- 324.4/324.4 kB 957.7 kB/s eta 0:00:00\n",
      "Downloading ydata_profiling-4.7.0-py2.py3-none-any.whl (357 kB)\n",
      "   -------------------------------------- 357.9/357.9 kB 968.4 kB/s eta 0:00:00\n",
      "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "   -------------------------------------- 296.5/296.5 kB 917.6 kB/s eta 0:00:00\n",
      "Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Downloading multimethod-1.11.2-py3-none-any.whl (10 kB)\n",
      "Downloading numba-0.59.1-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 2.6/2.6 MB 976.1 kB/s eta 0:00:00\n",
      "Downloading phik-0.12.4-cp39-cp39-win_amd64.whl (666 kB)\n",
      "   -------------------------------------- 666.3/666.3 kB 976.3 kB/s eta 0:00:00\n",
      "Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "   -------------------------------------- 394.9/394.9 kB 947.5 kB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.3-cp39-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 1.9/1.9 MB 981.9 kB/s eta 0:00:00\n",
      "Downloading numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "   ---------------------------------------- 14.7/14.7 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading statsmodels-0.14.1-cp39-cp39-win_amd64.whl (10.0 MB)\n",
      "   ---------------------------------------- 10.0/10.0 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "   -------------------------------------- 102.7/102.7 kB 848.1 kB/s eta 0:00:00\n",
      "Downloading wordcloud-1.9.3-cp39-cp39-win_amd64.whl (300 kB)\n",
      "   -------------------------------------- 300.6/300.6 kB 977.6 kB/s eta 0:00:00\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading llvmlite-0.42.0-cp39-cp39-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 28.1/28.1 MB 987.0 kB/s eta 0:00:00\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "   -------------------------------------- 233.9/233.9 kB 951.9 kB/s eta 0:00:00\n",
      "Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "   ---------------------------------------- 4.7/4.7 MB 1.0 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27092 sha256=4339e62dbac5719798e0e4146415d93927925c0a4a0c77804b4b8b75e92a8b8d\n",
      "  Stored in directory: c:\\users\\julia\\appdata\\local\\pip\\cache\\wheels\\1d\\05\\04\\c6d7d3b66539d9e659ac6dfe81e2d0fd4c1a8316cc5a403300\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: htmlmin, tangled-up-in-unicode, pydantic-core, numpy, multimethod, llvmlite, dacite, annotated-types, pydantic, patsy, numba, wordcloud, visions, statsmodels, phik, imagehash, ydata-profiling, pandas-profiling\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.37.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: visions 0.7.6 does not provide the extra 'type-image-path'\n",
      "WARNING: visions 0.7.5 does not provide the extra 'type-image-path'\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas-profiling\n",
    "\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perfilamiento y entendimiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('tipo2_entrenamiento_estudiantes.csv', sep=',', encoding = 'utf-8')\n",
    "# Asignación a una nueva variable de los datos leidos\n",
    "data_t=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muy buena atención y aclaración de dudas por p...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buen hotel si están obligados a estar cerca de...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es un lugar muy lindo para fotografías, visite...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abusados con la factura de alimentos siempre s...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuvimos un par de personas en el grupo que rea...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class\n",
       "0  Muy buena atención y aclaración de dudas por p...      5\n",
       "1  Buen hotel si están obligados a estar cerca de...      3\n",
       "2  Es un lugar muy lindo para fotografías, visite...      5\n",
       "3  Abusados con la factura de alimentos siempre s...      3\n",
       "4  Tuvimos un par de personas en el grupo que rea...      3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos que tenemos se presentan de una manera muy simple, una columna con las reseñas en lenguaje natural, y otra columna con la calificación numerica de las reseñas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Lenguaje de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el planteamiento de un modelo que analice textos, es esencial primero conocer el idioma en el que se encuentran los textos, esto porque tanto para la transformación de los textos (lematización, tokenización) para poder ser procesado por el modelo, como para configurar el modelo, es necesario que se tenga un lenguaje comun para todos los tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muy buena atención y aclaración de dudas por p...</td>\n",
       "      <td>5</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buen hotel si están obligados a estar cerca de...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es un lugar muy lindo para fotografías, visite...</td>\n",
       "      <td>5</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abusados con la factura de alimentos siempre s...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuvimos un par de personas en el grupo que rea...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>Me parece buen sistema, agiliza el transporte,...</td>\n",
       "      <td>4</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>Fue una escapada de un día desde el complejo, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>La Plaza de la Revolución es un lugar emblemát...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>Es la segunda ocasión que me quedo en los cuar...</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Llegamos por casualidad a Los Mercaderes, un g...</td>\n",
       "      <td>5</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7875 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class idioma\n",
       "0     Muy buena atención y aclaración de dudas por p...      5     es\n",
       "1     Buen hotel si están obligados a estar cerca de...      3     es\n",
       "2     Es un lugar muy lindo para fotografías, visite...      5     es\n",
       "3     Abusados con la factura de alimentos siempre s...      3     es\n",
       "4     Tuvimos un par de personas en el grupo que rea...      3     es\n",
       "...                                                 ...    ...    ...\n",
       "7870  Me parece buen sistema, agiliza el transporte,...      4     es\n",
       "7871  Fue una escapada de un día desde el complejo, ...      4     es\n",
       "7872  La Plaza de la Revolución es un lugar emblemát...      3     es\n",
       "7873  Es la segunda ocasión que me quedo en los cuar...      1     es\n",
       "7874  Llegamos por casualidad a Los Mercaderes, un g...      5     es\n",
       "\n",
       "[7875 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Podemos usar la libreria langdetect para conocer el idioma de todos los textos, y podemos aprovecharnos de las funcionalidades \n",
    "# de pandas para facilmente agregar una columna con el idioma del texto para su posterior analizis\n",
    "from langdetect import detect\n",
    "data_t['idioma'] = data_t['Review'].apply(detect)\n",
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "es    7866\n",
       "en       3\n",
       "it       3\n",
       "pt       2\n",
       "sq       1\n",
       "Name: idioma, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Podemos realizar el conteo de los valores en la columna idioma para entender la proporcion linguistica de las reseñas\n",
    "data_t['idioma'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos virtualmente todas las reseñas se encuentran en español, con tan solo 8 reseñas de 7874 perteneciendo a otro idioma.\n",
    "Como mencionabamos previamente, el modelo tiene que plantarse para un solo idioma, por lo que sera necesario remover las reseñas de otros idiomas en la fase de transformación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Entendimiento de los ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entender y analizar la distribución de los datos de los rating puede ayudarnos a contribuir cualitativamente los objetivos de negocios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7875.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.502603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.320435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Class\n",
       "count  7875.000000\n",
       "mean      3.502603\n",
       "std       1.320435\n",
       "min       1.000000\n",
       "25%       3.000000\n",
       "50%       4.000000\n",
       "75%       5.000000\n",
       "max       5.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las estadisticas de los ratings de las reseñas podemos entender lo siguiente:\n",
    "* No hay ratings invalidos dado que el maximo y el minimo se encuentran en una escala logica y consistente (1-5)\n",
    "* En promedio las reseñas tienen una calificación de 3.5, por lo que puede ser evidencia de que se tiene una distribución apropiada de calificaciones (no estan sesgadas a ningun extremo).\n",
    "* Lo anterior se puede confirmar observando la distribución de los datos en los cuartiles. El 25% de los ratings tienen una calificación maxima de 3, el 50% de 4, y el 75% de 5.\n",
    "* Tenemos 7875 reseñas para la creación del modelo y su posterior validación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Calidad de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Completitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0.0\n",
       "Class     0.0\n",
       "idioma    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((data_t.isnull().sum()/data_t.shape[0])).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que no tenemos valores nulos en nuestros datos, por lo tanto no sera necesario hacer un analizis de manejo de nulalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Unicidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t.duplicated(keep = False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que tenemos 102 registros duplicados, debido a que los duplicados no añaden valor alguno al modelo, pero si pueden introducir un sesgo (debido a que ciertas palabras pueden asosiarse de manera mas fuerte a un rating de manera erronea), tendremos que eliminarlos en la fase de limpieza de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Consistencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como veiamos previamente en el entendimiento de los ratings, estos datos son consistentes dado que todas las calificaciones se encuentran en un rango coherente y logico de (1-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4 Validez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que no existe una relación cuantificable entre las columnas, no tiene cabida un analisis de validez de las relaciones entre columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Limpieza de los datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Quitar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t= data_t.drop_duplicates()\n",
    "data_t.duplicated(keep = False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mencionamos previamente, tenemos que deshacernos de los duplicados antes de alimentar el modelo con los datos. Observamos que el dataframe queda sin datos duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Quitar reseñas en otros idiomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "es    7793\n",
       "Name: idioma, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t= data_t[data_t.idioma == 'es']\n",
    "data_t['idioma'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se menciono en el entendimiento de datos, nos vamos a quedar con solo las reseñas que esten en español. Podemos observar que el dataframe ahora solo contiene reseñas en español"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Transformar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocessing() missing 1 required positional argument: 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24660/2350348305.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: preprocessing() missing 1 required positional argument: 'words'"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"spanish\")\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "def to_lowercase(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(word.lower())\n",
    "    return new_words\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "def remove_stopwords(words):\n",
    "    stop_words = set(stopwords.words(\"spanish\"))\n",
    "    new_words = [word for word in words if word not in stop_words]\n",
    "    return new_words\n",
    "def preprocessing(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorización con TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=word_tokenize, stop_words=stop_words, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(X_train[\"Textos_espanol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary size:\", len(tfidf.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF: Clasificación con Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(random_state=5, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.fit(X_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_logistic_predict = logistic_model.predict(tfidf.transform(X_test[\"Textos_espanol\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_logistic_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_logistic = precision_score(y_test, y_test_logistic_predict, average='weighted')\n",
    "recall_logistic = recall_score(y_test, y_test_logistic_predict, average='weighted')\n",
    "f1_logistic = f1_score(y_test, y_test_logistic_predict, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision_logistic)\n",
    "print(\"Recall:\", recall_logistic)\n",
    "print(\"F1:\", f1_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF: Clasificación con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = RandomForestClassifier(random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.fit(X_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(tfidf_model.feature_importances_, index=tfidf.vocabulary_).sort_values().tail(20).plot.barh(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_estimators = tfidf_model.estimators_\n",
    "print(\"Number of trees:\", len(tfidf_estimators))\n",
    "print(\"Trees depth (mean):\", np.mean([tree.get_depth() for tree in tfidf_estimators]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tfidf_predict = tfidf_model.predict(X_tfidf)\n",
    "y_test_tfidf_predict = tfidf_model.predict(tfidf.transform(X_test[\"Textos_espanol\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_score(y_train, y_train_tfidf_predict,average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_train, y_train_tfidf_predict,average='weighted'))\n",
    "print(\"F1:\", f1_score(y_train, y_train_tfidf_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_score(y_test, y_test_tfidf_predict,average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_tfidf_predict,average='weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_test_tfidf_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF: Clasifiación con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear', random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.fit(X_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_svm_predict = svm_model.predict(tfidf.transform(X_test[\"Textos_espanol\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_svm_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_svm = precision_score(y_test, y_test_svm_predict, average='weighted')\n",
    "recall_svm = recall_score(y_test, y_test_svm_predict, average='weighted')\n",
    "f1_svm = f1_score(y_test, y_test_svm_predict, average='weighted')\n",
    "\n",
    "print(\"Precision (SVM):\", precision_svm)\n",
    "print(\"Recall (SVM):\", recall_svm)\n",
    "print(\"F1 (SVM):\", f1_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
